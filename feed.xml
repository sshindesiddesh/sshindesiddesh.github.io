<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sshindesiddesh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sshindesiddesh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-13T03:39:25+00:00</updated><id>https://sshindesiddesh.github.io/feed.xml</id><title type="html">blank</title><subtitle>Distributed Systems Engineer passionate about solving real-world problems at scale, with expertise in performance optimizations and resilient architectures. </subtitle><entry><title type="html">Thread Pool implementation</title><link href="https://sshindesiddesh.github.io/blog/2025/thread-pool-implementation/" rel="alternate" type="text/html" title="Thread Pool implementation"/><published>2025-05-12T00:07:41+00:00</published><updated>2025-05-12T00:07:41+00:00</updated><id>https://sshindesiddesh.github.io/blog/2025/thread-pool-implementation</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2025/thread-pool-implementation/"><![CDATA[<h3>Building a Time-Scheduled Thread Pool in C++17: An Interview Deep Dive</h3> <p>Before diving into the code implementation, let me summarize what we’ve created: a C++17-compatible thread pool that not only manages a fixed set of worker threads but also supports task scheduling at specific future time points. This implementation leverages modern C++ features and provides a clean, reusable interface that would be suitable for high-performance applications.</p> <h3>Design Overview</h3> <p>The thread pool implementation follows these key principles:</p> <ul><li><strong>Task Scheduling</strong>: Tasks can be scheduled to execute at specific time points</li><li><strong>Resource Management</strong>: Creates a fixed number of threads that are reused for multiple tasks</li><li><strong>Type Safety</strong>: Fully templated interface that preserves return types through futures</li><li><strong>Efficient Synchronization</strong>: Minimizes lock contention using condition variables</li></ul> <p>The core interface is straightforward:</p> <pre>template &lt;typename TaskType&gt;<br />future&lt;typename std::invoke_result&lt;TaskType&gt;::type&gt;<br />addTask(TaskType task, time_point&lt;steady_clock&gt; execute_at);</pre> <p>This allows adding any callable object to be executed at a specific time point, returning a future for the eventual result.</p> <h3>Implementation Deep Dive</h3> <h3>Task Representation and Priority Queue</h3> <pre>struct Task {<br />  std::function&lt;void()&gt; execute_cb;<br />  time_point&lt;steady_clock&gt; execute_at;<br />};</pre> <pre>struct TaskComparator {<br />  bool operator()(const Task &amp;a, const Task &amp;b) {<br />    return a.execute_at &gt; b.execute_at;<br />  }<br />};<br />priority_queue&lt;Task, vector&lt;Task&gt;, TaskComparator&gt; pq;</pre> <p>The implementation uses a priority queue with a custom comparator to ensure tasks are ordered by their execution time</p> <p>. The comparator returns true when a should have lower priority than b, so we compare execution times in descending order to prioritize earlier time points.</p> <h3>Thread Management</h3> <pre>void startThreads() {<br />  for (int ii = 0; ii &lt; num_threads; ++ii) {<br />    thread_vec.emplace_back([this]() { worker(); });<br />  }<br />}</pre> <p>Worker threads are created during pool initialization, with each thread executing the worker() function. This approach avoids the overhead of creating and destroying threads for each task</p> <p>. The number of threads defaults to the hardware concurrency level, which is optimal for CPU-bound tasks</p> <h3>Task Submission and Type Preservation</h3> <pre>template &lt;typename TaskType&gt;<br />future&lt;typename std::invoke_result&lt;TaskType&gt;::type&gt;<br />addTask(TaskType task, time_point&lt;steady_clock&gt; execute_at) {<br />  <br />  using result_type = typename std::invoke_result&lt;TaskType&gt;::type;<br />  <br />  packaged_task&lt;result_type()&gt; ptask(std::move(task));<br />  auto fut = ptask.get_future();<br />  auto ptask_ptr =<br />      make_shared&lt;packaged_task&lt;result_type()&gt;&gt;(std::move(ptask));<br />  Task q_task;<br />  <br />  q_task.execute_cb = [ptask_ptr = std::move(ptask_ptr)]() {<br />    (*ptask_ptr)();<br />  };<br />  q_task.execute_at = execute_at;<br />  <br />  {<br />    unique_lock lk(qmtx);<br />    pq.push(std::move(q_task));<br />  }<br />  <br />  cv.notify_one();<br />  return fut;<br />}</pre> <p>This is where the magic happens:</p> <ol><li>We use std::invoke_result to determine the return type of the task</li><li>The task is wrapped in a std::packaged_task to handle execution and result retrieval</li><li>We get a future from the packaged task before moving the task into a shared_ptr</li><li>The shared_ptr is captured in a lambda that becomes our type-erased callback</li><li>We lock the queue mutex, push the task, and notify waiting threads</li><li>Finally, we return the future to the caller</li></ol> <p>The use of std::packaged_task provides a clean way to handle the task&#39;s return value through futures</p> <h3>Worker Thread Logic</h3> <pre>void worker() {<br />  while (true) {<br />    unique_lock lk(qmtx);<br />    cv.wait(lk, [this]() { return term || !pq.empty(); });<br />    if (term &amp;&amp; pq.empty()) {<br />          return;<br />    }<br />        <br />    auto &amp;task = pq.top();<br />    if (task.execute_at &lt;= steady_clock::now()) {<br />      auto execute_cb = std::move(task.execute_cb);<br />      pq.pop();<br />      lk.unlock();<br />      execute_cb();<br />    } else {<br />      cv.wait_until(lk, task.execute_at);<br />    }<br />  }<br />}</pre> <p>The worker thread algorithm:</p> <ol><li>Acquires the queue lock</li><li>Waits until there’s a task or termination is requested</li><li>If it’s time to terminate and there are no more tasks, exits</li><li>Checks if the top task’s execution time has arrived</li><li>If so, moves the task out of the queue, releases the lock, and executes the task</li><li>If not, waits until the task’s execution time</li></ol> <p>This design ensures threads aren’t busy-waiting when there’s no work to do, preserving CPU resources</p> <h3>Lock Primitives: A Closer Look</h3> <h3>std::mutex and std::unique_lock</h3> <p>The thread pool uses a mutex (qmtx) to protect access to the shared priority queue. Instead of directly locking and unlocking the mutex, we use std::unique_lock</p> <pre>unique_lock lk(qmtx);<br />// Critical section</pre> <p>Why std::unique_lock instead of std::lock_guard? While std::lock_guard provides simple RAII-based locking, std::unique_lock offers more flexibility:</p> <ol><li>It allows unlocking and relocking the mutex, which we do before task execution</li><li>It works with condition variables, which require the ability to release and reacquire the lock</li></ol> <p>As seen in our worker thread:</p> <pre>auto execute_cb = std::move(task.execute_cb);<br />pq.pop();<br />lk.unlock();  // Release lock before execution<br />execute_cb(); // Execute without holding the lock</pre> <p>This pattern prevents holding the lock during potentially long-running tasks, which would block other threads from accessing the queue</p> <h3>std::condition_variable</h3> <p>The condition variable (cv) allows threads to wait efficiently until a condition is met:</p> <pre>cv.wait(lk, [this]() { return term || !pq.empty(); });</pre> <p>Here, threads wait until either termination is requested or there’s a task in the queue. The condition variable integrates with the unique_lock to:</p> <ol><li>Release the lock while waiting</li><li>Reacquire the lock when notified</li><li>Check the predicate before continuing</li></ol> <p>We also use wait_until to have threads wake up at specific times for scheduled tasks:</p> <pre>cv.wait_until(lk, task.execute_at);</pre> <p>This is more efficient than continuously checking the time, as it leverages the operating system’s timer facilities</p> <p>.</p> <h3>Testing Strategy</h3> <p>The provided BasicTest() function demonstrates two key capabilities:</p> <ol><li>Scheduling tasks for future execution (10 seconds and 5 seconds in the future)</li><li>Handling multiple concurrent tasks with different execution times</li></ol> <pre>void BasicTest() {<br />  ThreadPool tp(std::thread::hardware_concurrency() /* num_threads */);<br />  vector&lt;future&lt;int&gt;&gt; future_vec;<br />  // Schedule 20 &quot;long&quot; tasks 10 seconds in the future<br />  for (int ii = 0; ii &lt; 20; ++ii) {<br />    auto fut = tp.addTask(<br />        []() {<br />          cout &lt;&lt; &quot; Long Task &quot; &lt;&lt; endl;<br />          return 0;<br />        },<br />        steady_clock::now() + steady_clock::duration(std::chrono::seconds(10)));<br />    future_vec.emplace_back(std::move(fut));<br />  }<br />  // Schedule 10 &quot;short&quot; tasks 5 seconds in the future<br />  for (int ii = 0; ii &lt; 10; ++ii) {<br />    auto fut = tp.addTask(<br />        []() {<br />          cout &lt;&lt; &quot; Short Task &quot; &lt;&lt; endl;<br />          return 0;<br />        },<br />        steady_clock::now() + steady_clock::duration(std::chrono::seconds(5)));<br />    future_vec.emplace_back(std::move(fut));<br />  }<br />  // Wait for all tasks to complete<br />  for (auto &amp;fut : future_vec) {<br />    fut.get();<br />  }<br />  tp.terminate();<br />}</pre> <p>Expected output (simplified):</p> <pre>Start running basic test<br />(After 5 seconds)<br />Short Task<br />Short Task<br />...<br />(After 10 seconds)<br />Long Task<br />Long Task<br />...</pre> <h3>Additional Test Cases to Consider</h3> <p>For a more comprehensive test suite:</p> <ol><li><strong>Past Time Points</strong>: Schedule tasks with time points in the past, verifying immediate execution</li><li><strong>Race Conditions</strong>: Rapidly add and execute tasks from multiple threads</li><li><strong>Task Exceptions</strong>: Ensure exceptions in tasks are properly captured in futures</li><li><strong>Cancelation</strong>: Add task cancelation capability and test it</li><li><strong>Long-Running Tasks</strong>: Verify that long-running tasks don’t block other scheduled tasks</li><li><strong>Resource Exhaustion</strong>: Test behavior when system resources are constrained</li><li><strong>Stress Testing</strong>: Submit thousands of tasks with varying execution times</li></ol> <h3>Potential Improvements</h3> <p>Several enhancements could be made to this thread pool:</p> <ol><li><strong>Dynamic Thread Management</strong>: Adjust thread count based on load</li><li><strong>Task Priorities</strong>: Add priority levels independent of execution time</li><li><strong>Task Cancelation</strong>: Allow canceling scheduled tasks</li><li><strong>Thread Affinity</strong>: Pin threads to specific CPU cores for better cache utilization</li><li><strong>Finer-Grained Locking</strong>: Use multiple mutex objects to reduce contention</li><li><strong>Work Stealing</strong>: Implement work stealing between thread queues</li></ol> <h3>Conclusion</h3> <p>This thread pool implementation showcases key C++17 features and threading concepts. Its elegant design provides type-safe task scheduling with minimal locking overhead. While there’s room for optimization, this core implementation serves as an excellent foundation for understanding concurrent programming patterns in modern C++.</p> <p>In an interview setting, this code demonstrates:</p> <ul><li>Strong understanding of concurrency primitives</li><li>Familiarity with modern C++ features</li><li>Ability to design clean, reusable interfaces</li><li>Awareness of performance considerations</li></ul> <p>The balance between simplicity and functionality makes this implementation a solid starting point for many concurrent applications.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fd217901118c" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Leetcode Pattern: Monotonic Stack</title><link href="https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-monotonic-stack/" rel="alternate" type="text/html" title="Leetcode Pattern: Monotonic Stack"/><published>2025-05-11T23:47:03+00:00</published><updated>2025-05-11T23:47:03+00:00</updated><id>https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-monotonic-stack</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-monotonic-stack/"><![CDATA[<p>A <strong>monotonic stack</strong> is a powerful data structure and algorithm pattern that maintains elements in either strictly increasing or decreasing order. It’s particularly useful for solving array-based problems that involve finding the next greater or smaller element, calculating spans, or identifying boundaries efficiently. Unlike brute-force approaches that might require O(n²) time complexity, monotonic stacks often solve these problems in just O(n) time, making them perfect for technical interviews.</p> <p>In this post, I’ll guide you through six classic LeetCode problems that leverage the monotonic stack pattern, from straightforward applications to more complex scenarios.</p> <h3>1. Daily Temperatures (LeetCode 739, Medium)</h3> <p><strong>Problem:</strong></p> <p>Given an array of integers temperatures representing daily temperatures, return an array answer such that answer[i] is the number of days you have to wait after the ith day to get a warmer temperature. If there is no future day for which this is possible, keep answer[i] = 0.</p> <p><strong>Example:</strong></p> <ul><li>Input: temperatures =[73][74][75][71][69][72][76][73]</li><li>Output: [1][1][4][2][1][1]</li><li>Explanation:</li><li>Day 0 (73°): Wait 1 day for a warmer temperature (74°)</li><li>Day 1 (74°): Wait 1 day for a warmer temperature (75°)</li><li>Day 2 (75°): Wait 4 days for a warmer temperature (76°)</li><li>Day 3 (71°): Wait 2 days for a warmer temperature (72°)</li><li>Day 4 (69°): Wait 1 day for a warmer temperature (72°)</li><li>Day 5 (72°): Wait 1 day for a warmer temperature (76°)</li><li>Day 6 (76°): No future warmer temperature (0)</li><li>Day 7 (73°): No future warmer temperature (0)</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def dailyTemperatures(self, nums: List[int]) -&gt; List[int]:<br />        stack = []<br />        ans = [0] * len(nums)<br />        for cur_day, cur_temp in enumerate(nums):<br />            while stack and cur_temp &gt; stack[-1][1]:<br />                past_day, past_temp = stack.pop()<br />                ans[past_day] = cur_day - past_day<br />            stack.append((cur_day, cur_temp))<br />        return ans</pre> <p><strong>Explanation:</strong></p> <p>This is a classic application of a monotonic decreasing stack. We store pairs of (day_index, temperature) in our stack. For each current temperature:</p> <ol><li>While the stack is not empty and the current temperature is warmer than the temperature at the top of the stack, we pop the stack.</li><li>For each popped entry, we calculate the waiting days by subtracting the past day from the current day.</li><li>We push the current day and temperature onto the stack.</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each element is pushed and popped at most once.<br/> <strong>Space Complexity:</strong> O(n) — In the worst case, the stack stores all temperatures.</p> <p><strong>Edge Cases:</strong></p> <ul><li>All increasing temperatures: Each temperature waits exactly 1 day</li><li>All decreasing temperatures: All answers are 0 except the last which is also 0</li><li>Single temperature: The answer is</li></ul> <h3>2. Next Greater Element II (LeetCode 503, Medium)</h3> <p><strong>Problem:</strong></p> <p>Given a circular integer array nums (i.e., the next element of nums[nums.length - 1] is nums), return the next greater number for every element in nums. The next greater number of a number x is the first greater number to its traversing-order next in the array, which means you could search circularly to find its next greater number. If it doesn&#39;t exist, return -1 for this number.</p> <p><strong>Example:</strong></p> <ul><li>Input: nums =[1][2][1]</li><li>Output: [2, -1, 2]</li><li>Explanation:</li><li>The next greater element for 1 is 2</li><li>The next greater element for 2 doesn’t exist (so output -1)</li><li>The next greater element for the last 1 is 2 (circling back to the beginning)</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def nextGreaterElements(self, nums):<br />        n = len(nums)<br />        nums = nums + nums  # Duplicate array to handle circular nature<br />        out = [-1] * n<br />        stack = []<br />        for index, val in enumerate(nums):<br />            while stack and stack[-1][1] &lt; val:<br />                out[(stack[-1][0]) % n] = val<br />                stack.pop()<br />            stack.append((index, val))<br />        return out</pre> <p><strong>Explanation:</strong></p> <p>This problem extends the classic “next greater element” problem by adding the circular array constraint. The elegant approach here:</p> <ol><li>Duplicate the array to simulate the circular nature (nums + nums)</li><li>Use a monotonic decreasing stack to track indices and values</li><li>When a greater element is found, update the result array while accounting for the circular nature using modulo operation</li><li>Continue until all elements are processed</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each element is processed at most twice.<br/> <strong>Space Complexity:</strong> O(n) — Stack size and duplicated array.</p> <p><strong>Edge Cases:</strong></p> <ul><li>Single element array: Return [-1]</li><li>All equal elements: All outputs are -1</li><li>Strictly increasing array: All outputs except the last are the next element; the last is -1</li></ul> <h3>3. Largest Rectangle in Histogram (LeetCode 84, Hard)</h3> <p><strong>Problem:</strong></p> <p>Given an array of integers heights representing the histogram&#39;s bar height where the width of each bar is 1, return the area of the largest rectangle in the histogram.</p> <p><strong>Example:</strong></p> <ul><li>Input: heights =[2][1][5][6][2][3]</li><li>Output: 10</li><li>Explanation: The largest rectangle has an area of 10 units (height 5 with width 2, formed by the 5 and 6 height bars)</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def largestRectangleArea(self, heights: List[int]) -&gt; int:<br />        &quot;&quot;&quot;<br />        Algorithm:<br />        - push -1 on the stack<br />        - keep pushing on the stack if the cur height is greater than one on the top of the stack<br />            - keep only indexes in the stack<br />        - while popping any height<br />            - the max rectangle with that height is <br />            - first height &lt; cur on the left and on the right.<br />            - i.e. cur - stack top - 1 * cur_height<br />        - add additional zero towards the end to make popping easy<br />        &quot;&quot;&quot;<br />        heights.append(0)  # Add sentinel to ensure all bars are processed<br />        stack = [-1]  # Initialize with -1 to handle edge cases<br />        ans = 0<br />        <br />        for index in range(len(heights)):<br />            while stack[-1] != -1 and heights[stack[-1]] &gt; heights[index]:<br />                ans_index = stack.pop()<br />                left, right = stack[-1], index<br />                ans = max(ans, (right - left - 1) * heights[ans_index])<br />            stack.append(index)<br />        return ans</pre> <p><strong>Explanation:</strong></p> <p>This is a more complex application of monotonic stacks. The key insight:</p> <ol><li>For each bar, the maximum rectangle with that bar as the height extends to the nearest shorter bar on both sides</li><li>We use a monotonic increasing stack to track indices</li><li>When we find a shorter bar, we pop the stack and calculate rectangles</li><li>The sentinel value 0 at the end ensures all bars are processed</li><li>The sentinel -1 at the beginning helps calculate widths correctly</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each bar is pushed and popped exactly once.<br/> <strong>Space Complexity:</strong> O(n) — Stack size in worst case.</p> <p><strong>Edge Cases:</strong></p> <ul><li>Single bar: Area is the height of that bar</li><li>All bars same height: Area is height * number of bars</li><li>Empty array: Return 0</li></ul> <h3>4. Number of Visible People in a Queue (LeetCode 1944, Hard)</h3> <p><strong>Problem:</strong></p> <p>There are n people standing in a queue, numbered from 0 to n-1 in left to right order. You are given an array heights of distinct integers where heights[i] represents the height of the ith person. A person can see another person to their right in the queue if everybody in between is shorter than both of them. More formally, the ith person can see the jth person if i &lt; j and min(heights[i], heights[j]) &gt; max(heights[i+1], heights[i+2], ..., heights[j-1]). Return an array answer where answer[i] is the number of people the ith person can see to their right in the queue.</p> <p><strong>Example:</strong></p> <ul><li>Input: heights =[10][6][8][5][11][9]</li><li>Output: [3][1][2][1][1]</li><li>Explanation:</li><li>Person 0 (height 10) can see persons 1, 2, and 4</li><li>Person 1 (height 6) can see person 2</li><li>Person 2 (height 8) can see persons 3 and 4</li><li>Person 3 (height 5) can see person 4</li><li>Person 4 (height 11) can see person 5</li><li>Person 5 (height 9) can’t see anyone</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def canSeePersonsCount(self, heights: List[int]) -&gt; List[int]:<br />        stack = []<br />        ans = []<br />        n = len(heights)<br />        <br />        for x in range(n-1, -1, -1):<br />            ret = 0<br />            while stack and heights[x] &gt;= stack[-1]:<br />                stack.pop()<br />                ret += 1<br />            ans.append(ret + (1 if stack else 0))<br />            stack.append(heights[x])<br />        <br />        return ans[::-1]</pre> <p><strong>Explanation:</strong></p> <p>This solution uses a monotonic stack to track visible people, processing from right to left:</p> <ol><li>For each person, we count how many people they can see</li><li>We use a monotonic stack to maintain heights of people to the right</li><li>We pop people shorter than current person (they’re visible) and count them</li><li>If the stack is not empty after popping, the tallest remaining person is also visible</li><li>Finally, we reverse the answer since we processed from right to left</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each height is pushed and popped at most once.<br/> <strong>Space Complexity:</strong> O(n) — Stack size in worst case.</p> <p><strong>Edge Cases:</strong></p> <ul><li>Single person: Return</li><li>Strictly increasing heights: Each person sees only the next person</li><li>Strictly decreasing heights: Each person sees everyone to their right</li></ul> <h3>5. Verify Preorder Sequence in Binary Search Tree (LeetCode 255, Medium)</h3> <p><strong>Problem:</strong></p> <p>Given an array of unique integers preorder, return true if it is the correct preorder traversal sequence of a binary search tree.</p> <p><strong>Example:</strong></p> <ul><li>Input: preorder =[5][2][1][3][6]</li><li>Output: true</li><li>Explanation: This could be the preorder traversal of a BST with root 5, left subtree, and right subtree</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def verifyPreorder(self, preorder: List[int]) -&gt; bool:<br />        stack = []<br />        min_val = float(&quot;-inf&quot;)<br />        <br />        for val in preorder:<br />            while stack and stack[-1] &lt; val:<br />                min_val = max(min_val, stack.pop())<br />            <br />            if val &lt;= min_val:<br />                return False<br />                <br />            stack.append(val)<br />        return True</pre> <p><strong>Explanation:</strong></p> <p>This problem combines BST properties with monotonic stacks. The key insight:</p> <ol><li>In a valid preorder traversal, once we start visiting a right subtree, all subsequent values must be greater than all ancestors of that right subtree</li><li>We use a stack to simulate the traversal</li><li>When we encounter a value greater than the stack top, we’re moving to a right subtree</li><li>We keep track of a minimum value (min_val) that all future nodes must exceed</li><li>If a value is less than or equal to this minimum, the preorder sequence is invalid</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each element is processed exactly once.<br/> <strong>Space Complexity:</strong> O(n) — Stack size in worst case.</p> <p><strong>Edge Cases:</strong></p> <ul><li>Single element: Always valid</li><li>Sorted array (increasing): Valid preorder of a right-skewed BST</li><li>Sorted array (decreasing): Valid preorder of a left-skewed BST</li></ul> <h3>6. Remove K Digits (LeetCode 402, Medium)</h3> <p><strong>Problem:</strong></p> <p>Given string num representing a non-negative integer, and an integer k, return the smallest possible integer after removing k digits from num.</p> <p><strong>Example:</strong></p> <ul><li>Input: num = &quot;1432219&quot;, k = 3</li><li>Output: &quot;1219&quot;</li><li>Explanation: Remove the three digits 4, 3, and 2 to form the new number 1219 which is the smallest.</li></ul> <p><strong>Python Solution:</strong></p> <pre>class Solution:<br />    def removeKdigits(self, num, k):<br />        st = []<br />            <br />        for n in num:<br />            while st and st[-1] &gt; n and k:<br />                st.pop()<br />                k -= 1<br />            if st or n != &#39;0&#39;:<br />                st.append(n)<br />        <br />        if k:<br />            st = st[0:-k]<br />        return &#39;&#39;.join(st) or &#39;0&#39;</pre> <p><strong>Explanation:</strong></p> <p>This problem is a perfect application of a monotonic increasing stack:</p> <ol><li>We want to maintain the smallest possible number, which means keeping digits in increasing order</li><li>When we encounter a digit smaller than the top of our stack, we remove the top (if we still have removals left)</li><li>This greedy approach ensures we’re always removing the largest possible digit</li><li>We handle leading zeros by only adding a digit if the stack is non-empty or the digit is not ‘0’</li><li>If we still have removals left after processing all digits, we remove from the end</li><li>If the final result is empty, we return “0”</li></ol> <p><strong>Time Complexity:</strong> O(n) — Each digit is processed at most twice.<br/> <strong>Space Complexity:</strong> O(n) — Stack size in worst case.</p> <p><strong>Edge Cases:</strong></p> <ul><li>Empty string: Return “0”</li><li>k equals length of num: Return “0”</li><li>num is already the smallest possible: Remove the last k digits</li></ul> <h3>Tips and Tricks for Monotonic Stack Problems</h3> <p><strong>Pattern Recognition:</strong></p> <ul><li>Look for problems about finding the next greater/smaller element.</li><li>Problems involving ranges, spans, or heights often benefit from monotonic stacks.</li><li>Questions about maintaining a “view” or visibility usually suggest this pattern.</li></ul> <p><strong>Stack Type Selection:</strong></p> <ul><li>Use a monotonic <strong>increasing</strong> stack when looking for next/previous <strong>smaller</strong> elements.</li><li>Use a monotonic <strong>decreasing</strong> stack when looking for next/previous <strong>greater</strong> elements.</li><li>Remember: “Increasing stack finds smaller elements, decreasing stack finds greater elements”.</li></ul> <p><strong>Implementation Efficiency:</strong></p> <ul><li>Store indices in the stack rather than values when you need position information.</li><li>Use sentinels (like -1, 0, or infinity values) to handle edge cases elegantly.</li><li>Consider processing the array in reverse for “previous” element problems.</li></ul> <p><strong>Circular Array Handling:</strong></p> <ul><li>For circular arrays, either duplicate the array or use modulo arithmetic.</li><li>Use a second pass through the array or extend the array conceptually.</li></ul> <p><strong>Greedy Decision Making:</strong></p> <ul><li>Monotonic stacks inherently implement a greedy strategy.</li><li>For optimization problems (like Remove K Digits), the stack maintains the optimal solution.</li></ul> <p>Happy coding, and good luck with your next interview!</p> <p><em>Follow me for more algorithm insights and Python solutions!</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=88f1fc3f4455" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Leetcode Pattern: Parentheses</title><link href="https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-parentheses/" rel="alternate" type="text/html" title="Leetcode Pattern: Parentheses"/><published>2025-05-04T15:58:04+00:00</published><updated>2025-05-04T15:58:04+00:00</updated><id>https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-parentheses</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2025/leetcode-pattern-parentheses/"><![CDATA[<p>Parenthesis problems are a staple of coding interviews and algorithm practice. They test your understanding of stacks, recursion, and string manipulation. In this post, I’ll walk you through some classic and challenging LeetCode parenthesis questions, from easy to hard, with sample Python solutions.</p> <h3>1. Valid Parentheses (Leetcode 20, Easy)</h3> <p>Problem:<br/>Given a string containing just the characters &#39;(&#39;, &#39;)&#39;, &#39;{&#39;, &#39;}&#39;, &#39;[&#39; and &#39;]&#39;, determine if the input string is valid. An input string is valid if:</p> <ul><li>Open brackets are closed by the same type of brackets.</li><li>Open brackets are closed in the correct order.</li></ul> <p>Example:</p> <ul><li>Input: s = &quot;({[]})&quot;</li><li>Output: True</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def isValid(self, s: str) -&gt; bool:<br />        bracket_map = {&#39;)&#39;:&#39;(&#39;,&#39;]&#39;:&#39;[&#39;,&#39;}&#39;:&#39;{&#39;}<br />        st = []<br />        for c in s:<br />            if c not in bracket_map:<br />                st.append(c)<br />            else:<br />                if not st or st[-1] != bracket_map[c]:<br />                    return False<br />                st.pop()<br />        return not st</pre> <p>Time Complexity: O(n)<br/>Space Complexity: O(n) (stack)</p> <p>Edge Cases:</p> <ol><li>Empty string: &quot;&quot; → Valid.</li><li>All opening brackets: &quot;(((&quot; → Invalid.</li><li>Mixed types: &quot;([)]&quot; → Invalid.</li></ol> <h3>2. Valid Parenthesis String (Leetcode 678, Medium)</h3> <p>Problem:<br/>Given a string containing &#39;(&#39;, &#39;)&#39;, and &#39;*&#39;, where &#39;*&#39; can be treated as &#39;(&#39;, &#39;)&#39;, or an empty string, determine if the string is valid.</p> <p>Example:</p> <ul><li>Input: s = &quot;(*))&quot;</li><li>Output: True</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />  def checkValidString(s: str) -&gt; bool:<br /><br />    def isValid(opening, closing, s):<br />      open_cnt = 0<br />      for c in s:<br />          if c == opening or c == &quot;*&quot;:<br />              open_cnt += 1<br />          elif c == closing:<br />              if open_cnt &lt;= 0:<br />                  return False<br />              open_cnt -= 1<br />      return True<br /><br />    return isValid(&quot;(&quot;, &quot;)&quot;, s) and isValid(&quot;)&quot;, &quot;(&quot;, s[::-1])</pre> <p>Explanation:<br/>We scan the string twice: left-to-right and right-to-left, treating &#39;*&#39; as both open and close. This greedy approach ensures every &#39;)&#39; can be matched.</p> <p>Time Complexity: O(n)<br/>Space Complexity: O(1)</p> <p>Edge Cases:</p> <ol><li>All stars: &quot;***&quot; → Valid.</li><li>No stars: &quot;(()&quot; → Invalid.</li><li>Stars as closers: &quot;(*)&quot; → Valid.</li></ol> <h3>3. Generate Parentheses (Leetcode 22, Medium)</h3> <p>Problem:<br/>Given n pairs of parentheses, generate all combinations of well-formed parentheses.</p> <p>Example:</p> <ul><li>Input: n = 3</li><li>Output: [&quot;((()))&quot;,&quot;(()())&quot;,&quot;(())()&quot;,&quot;()(())&quot;,&quot;()()()&quot;]</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def generateParenthesis(self, n: int) -&gt; List[str]:<br />      out = []<br />      def dfs(open, close, path):<br />        if close == n:<br />            if open == close:<br />                out.append(&quot;&quot;.join(path))<br />            return<br />        if open &lt; n:<br />            dfs(open + 1, close, path + [&quot;(&quot;])<br />        if close &lt; open:<br />            dfs(open, close+1, path + [&quot;)&quot;])<br />      <br />      dfs(0, 0, [])<br />      return out</pre> <p>Explanation:<br/>This uses backtracking to generate all valid combinations, ensuring that at any time, the number of closing parentheses does not exceed the number of opening ones.</p> <p>Time Complexity: O(4^n / √n) (Catalan number)<br/>Space Complexity: O(n) (recursion stack)</p> <p>Edge Cases:</p> <ol><li>n = 1 → [&quot;()&quot;].</li><li>n = 0 → [].</li><li>n = 2 → [&quot;(())&quot;, &quot;()()&quot;].</li></ol> <h3>4. Minimum Remove to Make Valid Parentheses (Leetcode 1249, Medium)</h3> <p>Problem:<br/>Given a string with parentheses and lowercase letters, remove the minimum number of brackets to make it valid.</p> <p>Example:</p> <ul><li>Input: s = &quot;a)b(c)d&quot;</li><li>Output: &quot;ab(c)d&quot;</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def minRemoveToMakeValid(self, s: str) -&gt; str:<br />        def getValid(s, openb):<br />            rs = []<br />            open_cnt = 0<br />            for c in s:<br />                if c == openb:<br />                    open_cnt += 1<br />                    rs.append(c)<br />                elif c == &#39;(&#39; or c == &#39;)&#39;:<br />                    if open_cnt &gt; 0:<br />                        open_cnt -= 1<br />                        rs.append(c)<br />                else:<br />                    rs.append(c)<br />            return &quot;&quot;.join(rs)<br />        <br />        s = getValid(s, &quot;(&quot;)  # Remove invalid &#39;)&#39;<br />        s = getValid(s[::-1], &quot;)&quot;)  # Remove invalid &#39;(&#39; (reverse string)<br />        return s[::-1]</pre> <p>Explanation:</p> <ol><li>First pass removes invalid closing brackets.</li><li>Reverse the string and remove invalid opening brackets.</li></ol> <p>Time Complexity: O(n)<br/>Space Complexity: O(n)</p> <p>Edge Cases:</p> <ol><li>All invalid: &quot;))((&quot; → &quot;&quot;.</li><li>No brackets: &quot;abc&quot; → &quot;abc&quot;.</li><li>Nested brackets: &quot;())()(((&quot; → &quot;()()&quot;.</li></ol> <h3>5. Minimum Add to Make Parentheses Valid (Leetcode 921, Medium)</h3> <p>Problem:<br/>Return the minimum number of additions needed to make parentheses valid.</p> <p>Example:</p> <ul><li>Input: s = &quot;())&quot;</li><li>Output: 1 (Add &#39;(&#39; at the start).</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def minAddToMakeValid(self, s: str) -&gt; int:<br />        ans, open = 0, 0<br />        for c in s:<br />            if c == &quot;(&quot;:<br />                open += 1<br />            else:<br />                if open &gt; 0:<br />                    open -= 1<br />                else:<br />                    ans += 1<br />        return ans + open</pre> <p>Explanation:<br/>Track unmatched opening and closing brackets.</p> <p>Time Complexity: O(n)<br/>Space Complexity: O(1)</p> <p>Edge Cases:</p> <ol><li>Empty string: &quot;&quot; → 0.</li><li>All closing: &quot;))&quot; → 2.</li><li>All opening: &quot;(((&quot; → 3.</li></ol> <h3>6. Longest Valid Parentheses (Leetcode 32, Hard)</h3> <p>Problem:<br/>Find the length of the longest valid parentheses substring.</p> <p>Example:</p> <ul><li>Input: s = &quot;)()())&quot;</li><li>Output: 4 (substring &quot;()()&quot;).</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def longestValidParentheses(self, s: str) -&gt; int:<br />        def validLen(s, left_paren):<br />            ans = left = right = 0<br />            for c in s:<br />                if c == left_paren:<br />                    left += 1<br />                else:<br />                    right += 1<br />                if left == right:<br />                    ans = max(ans, left * 2)<br />                elif right &gt; left:<br />                    left = right = 0<br />            return ans<br />        <br />         return max(validLen(s, &quot;(&quot;), validLen(s[::-1], &quot;)&quot;))</pre> <p>Explanation:<br/>Two passes (left-to-right and right-to-left) to catch all valid substrings.</p> <p>Time Complexity: O(n)<br/>Space Complexity: O(1)</p> <p>Edge Cases:</p> <ol><li>All valid: &quot;(()())&quot; → 6.</li><li>Alternating: &quot;)()())&quot; → 4.</li><li>Single pair: &quot;()&quot; → 2.</li></ol> <h3>7. Remove Invalid Parentheses (Leetcode 301, Hard)</h3> <p>Problem:<br/>Remove the minimum number of brackets to make the string valid. Return all possible results.</p> <p>Example:</p> <ul><li>Input: s = &quot;()())()&quot;</li><li>Output: [&quot;()()()&quot;, &quot;(())()&quot;]</li></ul> <p>Python Solution:</p> <pre>class Solution:<br />    def removeInvalidParentheses(self, s: str) -&gt; List[str]:<br />        left, right = 0, 0<br />        for c in s:<br />            if c == &quot;(&quot;:<br />                left += 1<br />            elif c == &quot;)&quot;:<br />                if left &gt; 0:<br />                    left -= 1<br />                else:<br />                    right += 1                <br />        valid_len = len(s) - left - right<br /><br />        ans = set()<br />        def rec(index, opn, valid_len, path):<br />            if valid_len == 0:<br />                if opn == 0: ans.add(&quot;&quot;.join(path))<br />                return<br />            <br />            if index == len(s):<br />                return<br />            <br />            char = s[index]<br />            if char == &quot;(&quot;:<br />                # Include &#39;(&#39;<br />                path.append(char)<br />                rec(index + 1, opn + 1, valid_len - 1, path)<br />                path.pop()<br />                # Skip &#39;(&#39;<br />                rec(index + 1, opn, valid_len, path)<br />            elif char == &quot;)&quot;:<br />                if opn &gt; 0:<br />                    # Include &#39;)&#39;<br />                    path.append(char)<br />                    rec(index + 1, opn - 1, valid_len - 1, path)<br />                    path.pop()<br />                # Skip &#39;)&#39;<br />                rec(index + 1, opn, valid_len, path)<br />            else:<br />                # Include non-parenthesis character<br />                path.append(char)<br />                rec(index + 1, opn, valid_len - 1, path)<br />                path.pop()<br />        rec(0, 0, valid_len, [])<br />        return list(ans)</pre> <p>Explanation:<br/>Backtracking to generate all valid combinations by removing excess brackets.</p> <p>Time Complexity: O(2^n) (worst case)<br/>Space Complexity: O(n) (recursion stack)</p> <p>Edge Cases:</p> <ol><li>No valid solution: &quot;)(&quot; → [&quot;&quot;].</li><li>Multiple solutions: &quot;()())()&quot; → [&quot;()()()&quot;, &quot;(())()&quot;].</li><li>All characters: &quot;a)b(c)d&quot; → [&quot;ab(c)d&quot;].</li></ol> <h3>Tips and Tricks for Interviews</h3> <ol><li>Stack Usage: For validation and tracking nested structures.</li><li>Counter Variables: Track open/close counts.</li><li>Two-Pass Approach: For problems requiring bidirectional checks.</li><li>Backtracking: Generate all valid combinations.</li><li>Edge Cases: Always test empty strings, all valid/invalid brackets towards start and end of the input, and mixed characters.</li></ol> <p>Happy Coding!<br/><em>Follow me for more algorithm insights and Python solutions!</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f0cbc8447b04" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">In Memory Database Optimisations</title><link href="https://sshindesiddesh.github.io/blog/2024/in-memory-database-optimisations/" rel="alternate" type="text/html" title="In Memory Database Optimisations"/><published>2024-05-06T21:50:14+00:00</published><updated>2024-05-06T21:50:14+00:00</updated><id>https://sshindesiddesh.github.io/blog/2024/in-memory-database-optimisations</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2024/in-memory-database-optimisations/"><![CDATA[<p>In Memory Database Optimisations</p> <h3>Umbra- Disk-Based System with In-Memory Performance</h3> <h3>Abstract</h3> <p>Paper proposes that with by introducing a low overhead buffer manager with variable-size pages a comparable performance to in-memory database system (for the cached working set) can be achieved by a SSD based system.</p> <h3>Observations</h3> <p>Two hardware trends that cast strong doubt on pure in-memory systems. First, affordable RAM sizes are not increasing significantly anymore (&gt; 2TB are extremely costly). Second, SSDs have achieved astonishing improvements (3.5 GBps) while costing only $500.</p> <p>Combining large main memory buffers with fast SSDs is an attractive alternative as the cost is much lower and performance can be nearly as good.</p> <h3>Umbra</h3> <p>Genuine in-memory performance on the cached working set, and transparent scaling beyond main memory where required.</p> <h3>Buffer Manger</h3> <p>Combines low overhead buffering with variable-size pages.</p> <p>Buffer Pool memory mangement</p> <p>Pointer Swizzling</p> <p>Versioned Latches</p> <p>Buffer-Managed Relations</p> <p>Recovery</p> <h3>Further Considerations</h3> <p>String Handling</p> <p>Statistics</p> <p>Compilation &amp; Execution</p> <h3>Related Work</h3> <h3>Conclusion</h3> <p>Umbra can achieve in-memory performance if the entire dataset fits into RAM, while fully utilizing the available disk I/O bandwidth if the data has to be spilled to disk. Introduced a novel low overhead buffer manager that renders this kind of performance possible. Also investigated key adaptations to other components of an in-memory database system that are required for the transition to an SSD-based system.</p> <h3>Reference</h3> <p><a href="https://drive.google.com/file/d/1NpRTD28S_5MU9M8kRlxBGWlktRf_c4fN/view?usp=drive_link">https://drive.google.com/file/d/1NpRTD28S_5MU9M8kRlxBGWlktRf_c4fN/view?usp=drive_link</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4c8c11cf34b2" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Paxos Consensus Algorithm</title><link href="https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm/" rel="alternate" type="text/html" title="Paxos Consensus Algorithm"/><published>2024-03-18T21:58:49+00:00</published><updated>2024-03-18T21:58:49+00:00</updated><id>https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm/"><![CDATA[<p>Ironically, the abstract of the paper ‘Paxos made simple’ says ‘The Paxos algorithm, when presented in plain English, is very simple.’ Unfortunately most of the Distributed Systems students fail to grasp this for the first few times. This blog makes an attempt to be a refresher for ‘Paxos Consensus Algorithm’ and provides handy reference to the crux of the consensus algorithm with some optional details towards the end.</p> <h3>The problem</h3> <p>Assume a collection of processes that can propose values. A consensus algorithm ensures that a single one among the proposed values is chosen.<br/> • Only a value that has been proposed may be chosen,<br/> • Only a single value is chosen, and<br/> • A process never learns that a value has been chosen unless it actually has been chosen.<br/> • Some proposed value is eventually chosen and, if a value has<br/>been chosen, then a process can eventually learn the value.</p> <h3>Assumptions</h3> <p>• Processes operate at arbitrary speed, may fail by stopping, and may<br/>restart. Since they may fail after a value is chosen and then<br/>restart, a solution is impossible unless some information can be remembered by the process that has failed and restarted. Stable storage is required with every process.<br/> • Messages can take arbitrarily long to be delivered, can be duplicated,<br/>and can be lost, but they are not corrupted.</p> <h3>Roles</h3> <p>Proposer: Predetermined co-ordinator process. Also known as leader. Leader proposes values. In failure free case, there should be one leader.</p> <p>Acceptors: Collection of processes cooperate to choose a value.</p> <h3>Algorithm</h3> <p><strong>Phase 1<br/></strong>(a) A proposer selects a proposal number n and sends a <strong>prepare<br/>request</strong> with number n to a majority of acceptors.</p> <p>(b) If an acceptor receives a prepare request with number n greater<br/>than that of any prepare request to which it has already responded,<br/>then it responds to the request with a promise not to accept any more<br/>proposals numbered less than n and with the highest-numbered proposal (if any) that it has accepted.</p> <p><strong>Phase 2</strong> <br/>(a) If the proposer receives a response to its prepare requests<br/>(numbered n) from a majority of acceptors, then it sends an <strong>accept<br/>request</strong> to each of those acceptors for a proposal numbered n with a<br/>value v, where v is the value of the highest-numbered proposal among<br/>the responses, or is any value if the responses reported no proposals.</p> <p>(b) If an acceptor receives an accept request for a proposal numbered<br/>n, it accepts the proposal unless it has already responded to a prepare<br/>request having a number greater than n.</p> <p>What is this algorithm exactly?</p> <ul><li>Paxos requires selecting a new unique leader in case of the existing leader failure. Isn’t selecting a unique leader equivalent to solve the consensus problem? Paxos maintains consistency, never allowing two different values to be choosen, even if multiple processes think they are the leader. A unique non-faulty leader is required only to make sure that the progress is made.</li><li>Leader election can be performed using algorithm like ‘Stable leader election’ by Marcos K. Aguilera.</li><li>Today’s engineering systems use a more practical version of this algorithm as referenced in [4] and [5], but to understand them, understanding ‘Paxos made simple’ is must.</li></ul> <h3>References</h3> <ol><li>Paxos Made Simple — <a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">https://lamport.azurewebsites.net/pubs/paxos-simple.pdf</a></li><li>Consensus on Transaction Commit — <a href="https://lamport.azurewebsites.net/video/consensus-on-transaction-commit.pdf">https://lamport.azurewebsites.net/video/consensus-on-transaction-commit.pdf</a></li><li><a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=e030d116319970f636bf840c1e8af90857176d15">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=e030d116319970f636bf840c1e8af90857176d15</a></li><li>Paxos made Live — <a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf">https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf</a></li><li>Paxos made moderately complex — <a href="https://www.cs.cornell.edu/courses/cs7412/2011sp/paxos.pdf">https://www.cs.cornell.edu/courses/cs7412/2011sp/paxos.pdf</a></li></ol> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eb32ec165826" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Paxos Consensus Algorithm</title><link href="https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm/" rel="alternate" type="text/html" title="Paxos Consensus Algorithm"/><published>2024-02-10T10:00:00+00:00</published><updated>2024-02-10T10:00:00+00:00</updated><id>https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2024/paxos-consensus-algorithm/"><![CDATA[<p>Exploring the Paxos consensus algorithm, a fundamental building block for creating fault-tolerant distributed systems that can handle network partitions and node failures.</p>]]></content><author><name></name></author><category term="technical"/><category term="paxos"/><category term="distributed-systems"/><category term="consensus"/><category term="algorithms"/><summary type="html"><![CDATA[Understanding the Paxos consensus algorithm and its role in building fault-tolerant distributed systems]]></summary></entry><entry><title type="html">Thread Pool Implementation</title><link href="https://sshindesiddesh.github.io/blog/2024/thread-pool-implementation/" rel="alternate" type="text/html" title="Thread Pool Implementation"/><published>2024-01-15T10:00:00+00:00</published><updated>2024-01-15T10:00:00+00:00</updated><id>https://sshindesiddesh.github.io/blog/2024/thread-pool-implementation</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2024/thread-pool-implementation/"><![CDATA[<p>A comprehensive guide to implementing a thread pool in C++ for efficient concurrent programming and performance optimization in distributed systems.</p>]]></content><author><name></name></author><category term="technical"/><category term="threadpool"/><category term="c++"/><category term="concurrency"/><category term="performance"/><summary type="html"><![CDATA[Deep dive into implementing a high-performance thread pool in C++ for concurrent programming]]></summary></entry><entry><title type="html">What is a Solid State Drive (SSD)?</title><link href="https://sshindesiddesh.github.io/blog/2023/what-is-a-solid-state-drive-ssd/" rel="alternate" type="text/html" title="What is a Solid State Drive (SSD)?"/><published>2023-09-16T00:36:33+00:00</published><updated>2023-09-16T00:36:33+00:00</updated><id>https://sshindesiddesh.github.io/blog/2023/what-is-a-solid-state-drive-ssd</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2023/what-is-a-solid-state-drive-ssd/"><![CDATA[<h3>How does Solid State Drive (SSD) work?</h3> <p>The first commercial HDD was available in 1956 whereas flash memory was invented in the early 1980s and was first commercially available around 1991. This history matters because it is important to note that most of the early storage systems, file systems and database systems research was based on HDD being the primary underlying storage medium. In this blog we will first understand what is a SSD and in the follow up blogs we will explore how the software layers had to adapt to to this new storage medium.</p> <h4>What is a Solid State Drive (SSD)?</h4> <p>It is a non-volatile storage device that is commonly used in modern digital devices to store and retrieve data. It is a non-volatile input/output (IO) device for any computer based system. Most importantly it differs from the HDD in the sense that it is a solid state semiconductor device. Data is stored persistently in transistors. Yes, you are reading that right, persistently in transistors. This technology is popularly know as Flash storage these days and NAND Flash is the most widespread used one. SSDs are designed using this flash memory as storage medium.</p> <h4>Flash Memory</h4> <p>Flash chips are designed to store one or more bits in a single transistor; the level of charge trapped within the transistor is mapped to a binary value. In a single-level cell (SLC) flash, only a single bit is stored within a transistor (i.e., 1 or 0); with a multi-level cell (MLC) flash, two bits are encoded into different levels of charge. There is even triple-level cell (TLC) flash, which encodes 3 bits per cell. Overall, SLC chips achieve higher performance and are more expensive.</p> <h4>How does bit level storage operate?</h4> <p>You should only explore this if you are really interested in understanding the solid state device physics. No harm in skipping and continuing to the next section. <br/>- The basic NAND Flash cell. <a href="https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-1-the-basic-nand-flash-cell/">https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-1-the-basic-nand-flash-cell/</a><br/>- SLC, MLC and TLC NAND Flash. <a href="https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-2-slc-mlc-and-tlc-nand-flash/">https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-2-slc-mlc-and-tlc-nand-flash/</a></p> <h4>Flash Interface</h4> <p>The flash memory is organized in a very different way as compared to a basic block based interface for HDD.<br/><em>More details can be found in the following links:<br/></em><a href="https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-3-nand-architecture-strings-and-arrays/"><em>NAND Architecture</em></a><em><br/></em><a href="https://www.cactus-tech.com/resources/blog/details/solid-state-drive-primer-4-nand-architecture-pages-blocks/"><em>NAND Pages and Blocks</em></a></p> <p>Lets look at the basic operations provided by the flash memory:<br/><strong>Read</strong> (page, 512 bytes to 8KB): Read a page by specifying page number.<br/><strong>Erase</strong> (block, 128KB to few MBs): Before writing to a page within a flash, the nature of the device requires that you first erase the entire block the page lies by setting each bit to 1.<br/><strong>Program/Write</strong> (page): Once a block has been erased, the program com-<br/>mand can be used to change some of the 1’s within a page to 0’s</p> <p>Once a page has been written, the only way to modify its contents is to erase the entire block within which the page resides and then rewrite the data with modification.</p> <h4>Flash Reliability</h4> <p>As we use them as a storage medium, it is important to understand the reliability the dos/don’ts.</p> <p><strong>Wearout</strong>: when a flash block is erased and programmed, it slowly accrues a little bit of extra charge. Over time, as that extra charge builds up, it becomes increasingly difficult to differentiate between a 0 and a 1. At the point where it becomes impossible, the block becomes unusable. The typical lifetime of a block for SLC-based SSD is around 100,000 P/E cycles.</p> <p><strong>Disturbance</strong>: When accessing a particular page within a flash, it is possible that some bits get flipped in neighboring pages.</p> <h4>SSD architecture from raw Flash memory</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*khyMVaJ0WO5T-4AkewJefw.png"/><figcaption>A Flash based SSD: Logical Block Diagram</figcaption></figure> <p>For backward compatibility with HDDs, SSDs provide the same storage interface as HDDs. The standard storage interface is a simple block-<br/>based one, where blocks (sectors) of size 512 bytes (or larger) can be read or written, given a block address. The task of the flash-based SSD is to provide that standard block interface atop the raw flash chips inside it. Note that for flash, a page and block means different whereas for an operating system it may mean different.</p> <h4>Flash Translation Layer (FTL)</h4> <p>The essential functionality is to satisfy client reads and writes by turning them into internal flash operations. The FTL takes read and write requests on logical blocks (that comprise the device interface) and turns them into low-level read, erase, and program commands on the underlying physical blocks and physical pages. There are many approaches that have evolved over the years. The hybrid approach of keeping few page level mappings, many block level mappings and some erased pages to keep writing to is the one that is widely used today.</p> <h4>Flash Controller</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*VS9Jyaoc-567TuNF7smtXQ.png"/></figure> <h4>Garbage Collection</h4> <p>Because the Flash is written by page and erased by block, it is hard to keep the storage usage defragmented. On top of that, in order to maintain wea leveling and minimize read disturbance, SSDs try to balance out and spread new writes through out the flash. This leads to a new problem of periodically reclaiming dead blocks (with no live data) and erasing them. This is a background operation completely managed by the flash controller but may lead to some foreground performance inteference. To reduce GC costs, some manufacturers overprovision the the device by adding extra flash capacity.</p> <h4>Performance</h4> <p>Unlike hard disk drives, flash-based SSDs have no mechanical components, and in fact are in many ways more similar to DRAM, in that they are “random access” devices. The biggest difference in performance, as compared to disk drives, is realized when performing random reads and writes.</p> <h4>Comparison numbers</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*k1Yarx0EOS3em_EJF0TFsg.png"/><figcaption>HDD vs SSD sample performance measurements</figcaption></figure> <h4>Takeaways</h4> <p>- While the SSDs obtain tens or even hundreds of MB/s in random I/Os, this “high performance” hard drive has a peak of just a couple MB/s.<br/>- In terms of sequential performance, there is much less of a difference; while the SSDs perform better, a hard drive is still a good choice if sequential performance is all you need.<br/>- SSD random read performance is not as good as SSD random write performance.</p> <p><em>Then why haven’t SSDs completely replaced hard drives as the storage medium of choice?<br/>The answer is cost. SSD costs are 10 times more for per unit of storage.</em></p> <h4>Summary</h4> <p>These performance and cost differences dictate how large-scale stor- <br/>age systems are built. If performance is the main concern, SSDs are a <br/>terrific choice, particularly if random read performance is important. If, <br/>on the other hand, you are assembling a large data center and wish to <br/>store massive amounts of information, the large cost difference will drive you towards hard drives. Of course hybrid approach makes more sense for a sophisticated storage system.</p> <h4>References</h4> <p>- <a href="https://www.cactus-tech.com/resources/blog/details/solid-state-drives-101/">https://www.cactus-tech.com/resources/blog/details/solid-state-drives-101/</a><br/>- <a href="https://pages.cs.wisc.edu/~remzi/OSTEP/file-ssd.pdf">https://pages.cs.wisc.edu/~remzi/OSTEP/file-ssd.pdf</a><br/>- <a href="https://pages.cs.wisc.edu/~jhe/eurosys17-he.pdf">https://pages.cs.wisc.edu/~jhe/eurosys17-he.pdf</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c618cfa4dc62" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">How does Hard Disk Drive (HDD) work?</title><link href="https://sshindesiddesh.github.io/blog/2023/how-does-hard-disk-drive-hdd-work/" rel="alternate" type="text/html" title="How does Hard Disk Drive (HDD) work?"/><published>2023-09-15T23:48:25+00:00</published><updated>2023-09-15T23:48:25+00:00</updated><id>https://sshindesiddesh.github.io/blog/2023/how-does-hard-disk-drive-hdd-work</id><content type="html" xml:base="https://sshindesiddesh.github.io/blog/2023/how-does-hard-disk-drive-hdd-work/"><![CDATA[<p>In computer systems, one of the main challenges is persisting the information/data despite various failures. One of the oldest medium in use to persist information is Hard Disk Drives. In this blog post, lets try to deep dive into the famous storage medium, HDD.</p> <h4>What is a Hard Disk Drive (HDD)?</h4> <p>It is a non-volatile storage device that is commonly used in digital devices to store and retrieve data. It is a non-volatile input/output (IO) device for any computer based system.</p> <h4>What is the technology for storing data persistently?</h4> <p>Data is persistently stored on the HDD in binary format. Essentially it remembers a stream of 1s and 0s. HDD uses <strong>magnetic storage</strong> technology to store the data.</p> <h4>The Interface</h4> <p>The basic unit of interacting with HDD is a <strong>sector</strong>. Disk has sectors (generally 512 bytes to few KBs). Each sector is a unit that can be read or written. The sectors are numbered for 0 to n -1. Hence the disk can be viewed as an array of sectors. Multi-sector operations are possible, however, the only guarantee drive manufacturers make is that a single sector write is <strong>atomic</strong> (either complete entirely or fail entirely).</p> <h4>The Mechanical structure</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QcAwoMg-kKC4RZMpxLV4jA.png"/><figcaption>Stack of disk platters, heads and the HDD chassis</figcaption></figure> <ul><li><strong>Disk</strong>: A disk has one or more platters to store the data persistently</li><li><strong>Platter</strong>: a circular hard surface on which data is stored persistently.</li><li><strong>Spindle</strong>: The platters are all bound by the spindle at the centre.</li><li><strong>Motor</strong>: The spindle is connected to the motor which helps rotate all the platters at a constant speed (7000 to 15000 RPM) using a BLDC motor (Brush less DC).</li><li><strong>Surface</strong>: Aplatter has two sides called surfaces.</li><li><strong>Track</strong>: Data is encoded in concentric circles called tracks on each surface of the platter. A single surface may contain thousands of tracks. Latest HDDs can have more than 500k tracks.</li><li><strong>Sector</strong>: Each track is divided into sectors. Inner tracks have less sectors as compared to the outer tracks on the surface of the platter.</li><li><strong>Data in the sector</strong>:<br/> - preamble to identify the sector<br/> - address of this sector<br/> - user data<br/> - Error correcting code (ECC)</li><li><strong>Head stack assembly:</strong><br/> - One arm per surface, i.e. one arm below and one arm above each platter. <br/> - One read and one write head at the end of each arm.<br/> - Heads position could be adjusted anywhere on the radius of the platter to read/write from different tracks.</li></ul> <h4>Diagrams to illustrate the HDD structure</h4> <figure><img alt="A single track plus head. Numbers represent individual sectors on the track." src="https://cdn-images-1.medium.com/max/1024/1*c46PL5rQriZoZsQRKpD45w.png"/><figcaption>A HDD with one platter containing single track. The track has 4 sectors. Head is at sector 4. Platter rotates at constant speed around the spindle.</figcaption></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ImIPojczsaeK8qhXRaJvJA.png"/><figcaption>HDD with 1 platter which contains 2 tracks. Head seeks from one track to another and then starts reading the data. Numbers represent sectors on the track.</figcaption></figure> <h4>Physics behind reading/writing the data to the disk</h4> <ul><li>The disk platter is a Aluminium Magnesium alloy which has a special magnetic functional layer used to store bits by using the direction of the magnetic filed. The magnetic functional layer is on Cobalt, Chromium, Tantalum alloy 120nm wide. This has small magnetic regions whose direction could be manipulated via external magnetic field.</li><li>Writing data (1 bit): Done by manipulating the magnetization of a localized domain. Essentially changing the direction of the magnetic field of a single cell.</li><li>Reading data (1 bit): Done by reading the direction of the magnetic field from a single cell.</li><li>The key is that even if the head moves or the disk looses and regains power, the direction of the magnetic field in the region remains same. And this is where the <strong>persistence</strong> is achieved.</li><li>Important Note: While I have tried to make it conceptually simple, the way it is done is by keeping the change in magnetic field between two adjacent cells. But I guess, we can skip the details at this layer and below for now.</li></ul> <h4>Architecture of a HDD</h4> <ul><li>Don’t be surprised to find out that a HDD by itself has the following components at the least. Modern HDDs run sophisticated disk scheduling algorithms to get the maximum IO performance.</li><li><strong>Microprocessor</strong>: Functional program of the disk. It runs the disk scheduling algorithm.</li><li><strong>DRAM</strong>: Scratch pad for processor and buffer for the user data.</li><li><strong>BLDC</strong> motor power driver.</li><li><strong>SATA</strong> driver and port to connect to any other microprocessor.</li></ul> <h4>Numbers to remember as System Architect/Software Engineer</h4> <ul><li>Typical <strong>size</strong> of the HDDs: 1–8 TB</li><li><strong>Throughput</strong> (Data Transfer Rate):<br/> - The sequential read/write throughput of a consumer HDD is typically in the range of 100 to 200 megabytes per second (MB/s).<br/> - Enterprise-grade HDDs may offer slightly higher sequential throughput, ranging from 150 to 250 MB/s or more.</li><li><strong>Latency</strong>:<br/> - The average seek time for consumer HDDs is often in the range of 4 to 10 milliseconds (ms). This is the time it takes for the drive’s read/write head to move to the desired track.<br/> - Rotational latency, which is the time it takes for the target data sector to rotate under the read/write head, can add an additional 2 to 6 ms on average.<br/> - Therefore, the total latency for a consumer HDD might be in the range of 6 to 16 ms for random I/O operations.<br/>- Enterprise HDDs may have slightly lower seek and rotational latencies, but they are still relatively high compared to solid-state drives (SSDs).</li><li><strong>IOPS</strong> (Input/Output Operations Per Second):<br/>- For random read or write operations, a typical consumer-grade HDD may offer around 50 to 200 IOPS.<br/>- Enterprise-grade HDDs designed for data centers and server environments can provide higher IOPS, often in the range of 100 to 300 IOPS or more.</li><li>Note that these numbers vary a lot for every manufacturer and the model of the disk. I have pasted sample spec of two different HDDs, one optimized for capacity and the other for performance.</li></ul> <h4>Sample Specs</h4> <p>Cheetah is performance drive vs Barracuda is capacity drive</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/974/1*TfleaLqHPcxVLzkCsp01EA.png"/></figure> <h4>Latency math</h4> <p><em>T (I/O) = T (seek) + T (rotation) + T (transfer)</em></p> <h4>Summary</h4> <p><strong>So How to use HDDs efficiently?</strong><br/>- T(seek) + T(rotation) is the time required to start reading the data. For efficient use of the HDD, this needs to be minimized.<br/>- T(rotation) is relatively small and can be eliminated by purchasing the disk with high RPM (high performance disk).<br/>- T(seek) can be amortized and reduced by reading large amount of data or issuing IOs sequentially (read/write sectors physically closer to each other).<br/>- Now its easy to understand why random IOs on HDD may not have a good performance. T(seek) essentially may be required for every other IO which reduces disk performance. This is where the concept of data locality on the disk and random vs sequential IO performance originates.</p> <p>It’s important to note that HDDs are relatively slower and have higher latency as compared to <strong>solid-state drives (SSDs)</strong>. SSDs offer significantly higher IOPS, faster throughput, and much lower latency, which makes them a preferred choice for performance-critical applications and workloads that require rapid data access.</p> <p>We will go in depth of the SSDs in the next blog.</p> <h4>References</h4> <ul><li>All of the above information is coming from reading multiple text books, blogs, educational videos, etc. Please feel free to drop a message if you find any misleading information. Always ready to learn! I highly recommend reading the following chapter if you have some more time to explore: <a href="https://pages.cs.wisc.edu/~remzi/OSTEP/file-disks.pdf">https://pages.cs.wisc.edu/~remzi/OSTEP/file-disks.pdf</a></li><li>For quick visual understanding, watch this at 2x, <a href="https://www.youtube.com/watch?v=wtdnatmVdIg">https://www.youtube.com/watch?v=wtdnatmVdIg</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7ad6b9bfea63" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>